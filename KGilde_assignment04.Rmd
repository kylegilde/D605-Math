---
title: "DATA 605 FUNDAMENTALS OF COMPUTATIONAL MATHEMATICS" 
subtitle: "Assignment 4"
author: "Kyle Gilde"
date: "9/23/2017"
output: 
  prettydoc::html_pretty:
    theme: architect
    highlight: github
    toc: true
    toc_depth: 1
---
<style type="text/css">
body{
  font-family: Helvetica;
  font-size: 14pt;
}
</style>
<body>
```{r knitr_options, echo=FALSE}
knitr::opts_chunk$set(
                      warning = FALSE
                      ,error = FALSE
                      ,message = FALSE
                      ,tidy = TRUE
                      #,cache = TRUE
                      )
```


```{r packages, echo=F, collapse=T} 
load_packages <- c("prettydoc", "pracma",  "generalCorr", "subselect")

#see if we need to install any of them
install_load <- function(pkg){
  #CODE SOURCE: https://gist.github.com/stevenworthington/3178163
  new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
  if (length(new.pkg)) 
    install.packages(new.pkg, dependencies = TRUE)
  sapply(pkg, require, character.only = TRUE, quietly = TRUE, warn.conflicts = FALSE)
}

#excute function and display the loaded packages
data.frame(t(t(install_load(load_packages))), fix.empty.names = FALSE)
```

###1. Problem Set 1

In this problem, we’ll verify using R that SVD and Eigenvalues are related as worked out in the weekly module. Given a 3 × 2 matrix A

\begin{equation} A = 
\begin{bmatrix}
1, 2, 3 \\
−1, 0, 4
\end{bmatrix}
\end{equation}

```{r}
a <- c(1, 2, 3, −1, 0, 4)
(A <- matrix(a, 2, 3, byrow = T))
```


+ write code in R to compute $X = AA^T$ and $Y = A^TA$. 
```{r}
(X <- A %*% t(A))
(Y <- t(A) %*% A)
```

+ Then, compute the eigenvalues and eigenvectors of X and Y using the built-in commands in R. 
```{r}
(Xeigen <- eigen(X))
(Yeigen <- eigen(Y))
```

+ Then, compute the left-singular, singular values, and right-singular vectors of A using the svd command. 
```{r}
# d = singular values; u = left-singular vectors; v = right-singular vectors
(Asvd <- svd(A))
```

+ Examine the two sets of singular vectors and show that they are indeed eigenvectors of X and Y. 
```{r, collapse=T}
#eigenvectors of symmetric matrices have the following property

isTRUE(all.equal(X %*% Xeigen$vectors, Xeigen$vectors %*% diag(Xeigen$values)))
isTRUE(all.equal(Y %*% Yeigen$vectors, Yeigen$vectors %*% diag(Yeigen$values)))
```




```{r, collapse=T}
#If these 2 properties are still TRUE (nearly equal) when we substitute in right-singular and left-singular vectors, then these singular vectors are eigenvectors of X and Y.

isTRUE(all.equal(X %*% Asvd$u, Asvd$u %*% diag(Xeigen$values)))
isTRUE(all.equal(Y %*% Asvd$v, Asvd$v %*% diag(Yeigen$values[1:2])))
```


```{r, collapse=T}
# Additionally, the X and Y eigenvectors can be substituted into SVD.
isTRUE(all.equal(Asvd$u %*% diag(Asvd$d) %*% t(Asvd$v), A))
isTRUE(all.equal(Xeigen$vectors %*% diag(Asvd$d, 2, 3) %*% t(Yeigen$vector), A))
```

+ In addition, the two non-zero eigenvalues (the 3rd value will be very close to zero, if not zero) of both X and Y are the same 
```{r, collapse=T}
isTRUE(all.equal(Xeigen$values, Yeigen$values[1:2]))
```


+ and are squares of the non-zero singular values of A. 

```{r, collapse=T}
isTRUE(all.equal(Asvd$d, sqrt(Yeigen$values[1:2])))
isTRUE(all.equal(sqrt(Xeigen$values), Asvd$d))
```


Your code should compute all these vectors and scalars and store them in variables. Please add enough comments in your code to show me how to interpret your steps.

###2. Problem Set 2

Using the procedure outlined in section 1 of the weekly handout, write a function to compute the inverse of a well-conditioned full-rank square matrix using co-factors. 

In order to compute the co-factors, you may use built-in commands to compute the determinant. 

+ Your function should have the following signature: B = myinverse(A) 

+ where A is a matrix and B is its inverse and A×B = I. 

+ The off-diagonal elements of I should be close to zero, if not zero. Likewise, the diagonal elements should be close to 1, if not 1. 

+ Small numerical precision errors are acceptable but the function myinverse should be correct and must use co-factors and determinant of A to compute the inverse. 

Please submit PS1 and PS2 in an R-markdown document with your first initial and last name.


 
```{r, PS2}
rand_sq_matrix <- function(min_dim, max_dim, element_range){
  ###generate random square matrix###  
  dim_range <- c(min_dim:max_dim)
  samp_space <- c(-element_range:element_range)  
  
  m_dim <- sample(c(dim_range), 1)
  samp_size <- m_dim^2

  #select matrix elements
  rand_samp <- sample(samp_space, samp_size, replace = T)
  
  #create matrix
  current_matrix <- matrix(rand_samp, m_dim)

  return(current_matrix)
}

myinverse <- function(A){
  iMax <- nrow(A)
  jMax <- ncol(A)
  Adet <- det(A)
  #validate input
  if(iMax != jMax){
    result <- "Not a square matrix"
  } else if(Adet == 0){
    result <- "Singular matrix"
  } else if(qr(A)$rank != iMax){
    result <- "Rank-deficient matrix"
  } else {
    
    cof_matrix <- matrix(NA, iMax, jMax)
    
    for (i in 1:iMax){
      for (j in 1:jMax){
        cof_matrix[i, j] <- det(as.matrix(generalCorr::cofactor(A, i, j))) * (-1)^(i+j)
      }
      t_cof_matrix <- t(cof_matrix)
      #Outputs
      Ainverse <- t_cof_matrix / Adet
      A_x_Ainverse <- A %*% Ainverse
      condition <- cond(A)
      nearly_equal_to_I <- isTRUE(all.equal(A %*% Ainverse, diag(1, iMax)))
      nearly_equal_to_solveA <- isTRUE(all.equal(Ainverse, solve(A))) 
      
      result <- list(A = A,
                     Ainverse = Ainverse, 
                     A_x_Ainverse = A_x_Ainverse,
                     condition = condition, 
                     nearly_equal_to_I = nearly_equal_to_I, 
                     nearly_equal_to_solveA = nearly_equal_to_solveA
                     )
    }
  }
  return(result)
}

A <- rand_sq_matrix(3, 5, 20)
print(myinverse(A))

A <- rand_sq_matrix(3, 5, 20)
print(myinverse(A))

A <- rand_sq_matrix(3, 5, 20)
print(myinverse(A))
```


</body>